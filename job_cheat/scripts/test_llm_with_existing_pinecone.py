#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ê¸°ì¡´ Pinecone ë°ì´í„°ë¥¼ í™œìš©í•œ LLM í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ë¯¸ Pineconeì— ì €ì¥ëœ ë²¡í„° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬:
1. RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
2. LLM ì—­ëŸ‰ í‰ê°€ í…ŒìŠ¤íŠ¸
3. JSON í˜•ì‹ ì‘ë‹µ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List, Any

# Django ì„¤ì •
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "job_cheat.settings")

import django
django.setup()

from core.services.conversation_rag_service import ConversationRAGService
from core.services.gemini_service import GeminiService
from core.services.firebase_personas import update_persona_document

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_llm_with_existing_pinecone():
    """ê¸°ì¡´ Pinecone ë°ì´í„°ë¥¼ í™œìš©í•œ LLM í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    
    # ê¸°ì¡´ì— ì €ì¥ëœ ì‚¬ìš©ì ID (ì´ì „ í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©í•œ ê²ƒ)
    user_id = "test_user_structured_eval"  # ë˜ëŠ” "test_user_large_file"
    document_id = "chat_converted_structured"
    
    try:
        logger.info("=== ê¸°ì¡´ Pinecone ë°ì´í„°ë¥¼ í™œìš©í•œ LLM í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # 1ë‹¨ê³„: ëŒ€í™” RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("1ë‹¨ê³„: ëŒ€í™” RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        conversation_rag_service = ConversationRAGService()
        gemini_service = GeminiService()
        
        # 2ë‹¨ê³„: Pinecone ë°ì´í„° í™•ì¸
        logger.info("2ë‹¨ê³„: Pinecone ë°ì´í„° í™•ì¸ ì¤‘...")
        try:
            from core.services.pinecone_service import get_pinecone_service
            pinecone_service = get_pinecone_service()
            
            # ì¸ë±ìŠ¤ í†µê³„ í™•ì¸
            stats = pinecone_service.index.describe_index_stats()
            namespaces = stats.get('namespaces', {})
            
            if user_id in namespaces:
                namespace_stats = namespaces[user_id]
                vector_count = namespace_stats.get('vector_count', 0)
                logger.info(f"âœ… ì‚¬ìš©ì {user_id}ì˜ ë²¡í„° ìˆ˜: {vector_count}ê°œ")
            else:
                logger.warning(f"âš ï¸ ì‚¬ìš©ì {user_id}ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {list(namespaces.keys())}")
                return
                
        except Exception as exc:
            logger.error(f"âŒ Pinecone ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {exc}")
            return
        
        # 3ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        logger.info("3ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        test_queries = [
            "í”„ë¡œê·¸ë˜ë° ê¸°ìˆ ê³¼ ê°œë°œ ëŠ¥ë ¥",
            "í”„ë¡œì íŠ¸ ê´€ë¦¬ ë° íŒ€ í˜‘ì—…",
            "ë¬¸ì œ í•´ê²° ë° ì°½ì˜ì  ì‚¬ê³ ",
            "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë° ë¦¬ë”ì‹­"
        ]
        
        rag_results = {}
        for query in test_queries:
            logger.info(f"  ì¿¼ë¦¬: '{query}'")
            try:
                context = await conversation_rag_service.get_rag_context(
                    query=query,
                    user_id=user_id,
                    top_k=3
                )
                
                if context:
                    logger.info(f"  âœ… ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì„±ê³µ: {len(context):,}ì")
                    rag_results[query] = context
                else:
                    logger.warning(f"  âš ï¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    rag_results[query] = None
                    
            except Exception as exc:
                logger.error(f"  âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")
                rag_results[query] = None
        
        # 4ë‹¨ê³„: LLM ì—­ëŸ‰ í‰ê°€ í…ŒìŠ¤íŠ¸ (JSON í˜•ì‹)
        logger.info("4ë‹¨ê³„: LLM ì—­ëŸ‰ í‰ê°€ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        competencies = [
            {
                "name": "í”„ë¡œê·¸ë˜ë°_ê¸°ìˆ ",
                "description": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ê°œë°œ ë„êµ¬ì— ëŒ€í•œ ì´í•´ì™€ í™œìš© ëŠ¥ë ¥",
                "query": "í”„ë¡œê·¸ë˜ë° ê¸°ìˆ ê³¼ ê°œë°œ ëŠ¥ë ¥"
            },
            {
                "name": "í”„ë¡œì íŠ¸_ê´€ë¦¬", 
                "description": "í”„ë¡œì íŠ¸ ê¸°íš, ì¼ì • ê´€ë¦¬, íŒ€ í˜‘ì—…, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ëŠ¥ë ¥",
                "query": "í”„ë¡œì íŠ¸ ê´€ë¦¬ ë° íŒ€ í˜‘ì—…"
            },
            {
                "name": "ë¬¸ì œ_í•´ê²°",
                "description": "ë¬¸ì œ ë¶„ì„, í•´ê²°ì±… ë„ì¶œ, ë¹„íŒì  ì‚¬ê³ , ì°½ì˜ì  ì ‘ê·¼ ëŠ¥ë ¥", 
                "query": "ë¬¸ì œ í•´ê²° ë° ì°½ì˜ì  ì‚¬ê³ "
            },
            {
                "name": "í˜‘ì—…_ì†Œí†µ",
                "description": "íŒ€ì›Œí¬, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ê°ˆë“± í•´ê²°, ë¦¬ë”ì‹­ ëŠ¥ë ¥",
                "query": "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë° ë¦¬ë”ì‹­"
            }
        ]
        
        evaluation_results = {}
        
        for competency in competencies:
            logger.info(f"\n--- {competency['name']} ì—­ëŸ‰ í‰ê°€ ì¤‘... ---")
            
            # í•´ë‹¹ ì—­ëŸ‰ì— ëŒ€í•œ RAG ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            context = rag_results.get(competency['query'])
            
            if context:
                logger.info(f"RAG ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©: {len(context):,}ì")
                
                # LLM ì—­ëŸ‰ í‰ê°€ ìˆ˜í–‰
                evaluation_data = await evaluate_competency_with_citations(
                    competency_name=competency['name'],
                    competency_description=competency['description'],
                    context=context,
                    gemini_service=gemini_service
                )
                
                if evaluation_data:
                    logger.info(f"âœ… {competency['name']} ì—­ëŸ‰ í‰ê°€ ì™„ë£Œ")
                    logger.info(f"ì ìˆ˜: {evaluation_data.get('score', 'N/A')}/10")
                    
                    # Firestoreì— ì €ì¥
                    save_success = await save_competency_to_firestore(
                        user_id=user_id,
                        persona_id=document_id,
                        competency_data=evaluation_data
                    )
                    
                    if save_success:
                        evaluation_results[competency['name']] = evaluation_data
                        logger.info(f"âœ… {competency['name']} ê²°ê³¼ Firestore ì €ì¥ ì™„ë£Œ")
                    else:
                        logger.error(f"âŒ {competency['name']} ê²°ê³¼ Firestore ì €ì¥ ì‹¤íŒ¨")
                else:
                    logger.warning(f"âš ï¸ {competency['name']} ì—­ëŸ‰ í‰ê°€ ì‹¤íŒ¨")
            else:
                logger.warning(f"âš ï¸ {competency['name']}ì— ëŒ€í•œ RAG ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")
        
        # 5ë‹¨ê³„: ê²°ê³¼ ìš”ì•½
        logger.info("\n=== LLM ì—­ëŸ‰ í‰ê°€ ê²°ê³¼ ìš”ì•½ ===")
        for competency_name, result in evaluation_results.items():
            if result:
                logger.info(f"\nğŸ“Š {competency_name}:")
                logger.info(f"  ì ìˆ˜: {result.get('score', 'N/A')}/10")
                logger.info(f"  ê°•ì : {len(result.get('strengths', []))}ê°œ")
                logger.info(f"  ê°œì„ ì : {len(result.get('improvements', []))}ê°œ")
                logger.info(f"  í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {len(result.get('key_insights', []))}ê°œ")
                
                # ì²« ë²ˆì§¸ ê°•ì ê³¼ ê°œì„ ì  ì¶œë ¥
                strengths = result.get('strengths', [])
                if strengths:
                    logger.info(f"  ì£¼ìš” ê°•ì : {strengths[0].get('description', '')[:100]}...")
                
                improvements = result.get('improvements', [])
                if improvements:
                    logger.info(f"  ì£¼ìš” ê°œì„ ì : {improvements[0].get('description', '')[:100]}...")
        
        logger.info(f"\nâœ… ì´ {len(evaluation_results)}ê°œ ì—­ëŸ‰ í‰ê°€ ì™„ë£Œ")
        logger.info("=== ê¸°ì¡´ Pinecone ë°ì´í„°ë¥¼ í™œìš©í•œ LLM í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        
    except Exception as exc:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {exc}")
        raise


async def evaluate_competency_with_citations(
    competency_name: str,
    competency_description: str,
    context: str,
    gemini_service: GeminiService
) -> Dict[str, Any]:
    """ì‹¤ì œ ëŒ€í™” ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ì—­ëŸ‰ì„ í‰ê°€í•©ë‹ˆë‹¤."""
    
    evaluation_prompt = f"""
ë‹¤ìŒì€ í•œ ì‚¬ìš©ìì˜ ChatGPT ëŒ€í™” ê¸°ë¡ì—ì„œ ì¶”ì¶œí•œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

=== ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ===
{context}

=== í‰ê°€ ìš”ì²­ ===
{competency_name}: {competency_description}

=== í‰ê°€ ì§€ì¹¨ ===
1. ìœ„ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ {competency_name} ì—­ëŸ‰ì„ êµ¬ì²´ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
2. **ë°˜ë“œì‹œ ëŒ€í™” ë‚´ìš©ì—ì„œ ì‹¤ì œ ì¸ìš©ë¬¸ì„ í¬í•¨í•˜ì—¬ ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.**
3. ì¸ìš©í•  ë•ŒëŠ” "ì‚¬ìš©ì: [ì¸ìš©ë¬¸]" ë˜ëŠ” "ì–´ì‹œìŠ¤í„´íŠ¸: [ì¸ìš©ë¬¸]" í˜•ì‹ìœ¼ë¡œ ëª…í™•íˆ í‘œì‹œí•´ì£¼ì„¸ìš”.
4. ê°•ì ê³¼ ê°œì„ ì ì„ ê· í˜•ìˆê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. í‰ê°€ ì ìˆ˜(1-10ì )ì™€ í•¨ê»˜ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

=== ì‘ë‹µ í˜•ì‹ (JSON) ===
{{
    "competency_name": "{competency_name}",
    "score": 8,
    "score_explanation": "ì ìˆ˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª…",
    "strengths": [
        {{
            "description": "ê°•ì  ì„¤ëª…",
            "evidence": "ëŒ€í™”ì—ì„œ ì¸ìš©í•œ êµ¬ì²´ì  ê·¼ê±°",
            "citation": "ì‚¬ìš©ì: [ì‹¤ì œ ì¸ìš©ë¬¸]"
        }}
    ],
    "improvements": [
        {{
            "description": "ê°œì„ ì  ì„¤ëª…",
            "suggestion": "êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ",
            "evidence": "ëŒ€í™”ì—ì„œ ì¸ìš©í•œ êµ¬ì²´ì  ê·¼ê±°",
            "citation": "ì‚¬ìš©ì: [ì‹¤ì œ ì¸ìš©ë¬¸]"
        }}
    ],
    "overall_assessment": "ì „ì²´ì ì¸ í‰ê°€ ë° ì¢…í•© ì˜ê²¬",
    "key_insights": [
        "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1",
        "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2"
    ]
}}
"""
    
    try:
        # Geminië¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ í‰ê°€ ìˆ˜í–‰
        evaluation_result = await gemini_service.generate_structured_response(
            prompt=evaluation_prompt,
            response_format="json"
        )
        
        if evaluation_result:
            # JSON íŒŒì‹±
            try:
                evaluation_data = json.loads(evaluation_result.strip())
                return evaluation_data
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"ì›ë³¸ ì‘ë‹µ: {evaluation_result}")
                return None
        else:
            logger.warning("LLM í‰ê°€ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
            return None
            
    except Exception as exc:
        logger.error(f"ì—­ëŸ‰ í‰ê°€ ì‹¤íŒ¨: {exc}")
        return None


async def save_competency_to_firestore(
    user_id: str,
    persona_id: str,
    competency_data: Dict[str, Any]
) -> bool:
    """ì—­ëŸ‰ í‰ê°€ ê²°ê³¼ë¥¼ Firestoreì— ì €ì¥í•©ë‹ˆë‹¤."""
    
    try:
        # Firestore ë¬¸ì„œ ì—…ë°ì´íŠ¸ ë°ì´í„° êµ¬ì„±
        update_payload = {
            f"competencies.{competency_data['competency_name']}": {
                "score": competency_data.get("score", 0),
                "score_explanation": competency_data.get("score_explanation", ""),
                "strengths": competency_data.get("strengths", []),
                "improvements": competency_data.get("improvements", []),
                "overall_assessment": competency_data.get("overall_assessment", ""),
                "key_insights": competency_data.get("key_insights", []),
                "evaluated_at": "2025-01-27T16:00:00.000Z"  # ì‹¤ì œë¡œëŠ” í˜„ì¬ ì‹œê°„
            }
        }
        
        # Firestore ë¬¸ì„œ ì—…ë°ì´íŠ¸
        result = update_persona_document(
            user_id=user_id,
            persona_id=persona_id,
            payload=update_payload
        )
        
        if result:
            logger.info(f"âœ… {competency_data['competency_name']} ì—­ëŸ‰ í‰ê°€ ê²°ê³¼ Firestore ì €ì¥ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ {competency_data['competency_name']} ì—­ëŸ‰ í‰ê°€ ê²°ê³¼ Firestore ì €ì¥ ì‹¤íŒ¨")
            return False
            
    except Exception as exc:
        logger.error(f"Firestore ì €ì¥ ì‹¤íŒ¨: {exc}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    asyncio.run(test_llm_with_existing_pinecone())


if __name__ == "__main__":
    main()
