"""Gemini API ì—°ë™ ì„œë¹„ìŠ¤ ëª¨ë“ˆ."""

from __future__ import annotations

import logging
import os
from typing import Iterable, List, Optional

import google.generativeai as genai
from asgiref.sync import sync_to_async
from dotenv import load_dotenv


logger = logging.getLogger(__name__)


class GeminiServiceError(RuntimeError):
    """Gemini ì—°ë™ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜ˆì™¸."""


class GeminiService:
    """Gemini í…ìŠ¤íŠ¸/ì„ë² ë”© API ì—°ë™ ì„œë¹„ìŠ¤."""

    def __init__(self) -> None:
        load_dotenv()

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise GeminiServiceError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        genai.configure(api_key=api_key)

        self.text_model: str = os.getenv("GEMINI_TEXT_MODEL", "gemini-1.5-pro")
        self.embedding_model: str = os.getenv(
            "GEMINI_EMBEDDING_MODEL",
            "text-embedding-004",
        )

        self._generative_model = genai.GenerativeModel(self.text_model)

    async def generate_structured_response(
        self,
        prompt: str,
        *,
        response_format: str = "json",
    ) -> str:
        """í”„ë¡¬í”„íŠ¸ë¥¼ Gemini ëª¨ë¸ì— ì „ë‹¬í•´ ì‘ë‹µì„ ë°˜í™˜í•œë‹¤."""

        if not prompt:
            raise ValueError("prompt ê°’ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        logger.info(f"ğŸ”— Gemini API ì—°ê²° ì‹œì‘ - ëª¨ë¸: {self.text_model}")
        logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")
        logger.info(f"ğŸ“‹ ì‘ë‹µ í˜•ì‹: {response_format}")

        logger.info(f"ğŸ”§ í”„ë¡¬í”„íŠ¸ ì „ì²˜ë¦¬ ì‹œì‘")
        
        if response_format == "json":
            # JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸
            json_prompt = f"""
{prompt}

ì¤‘ìš”: ìœ„ ìš”ì²­ì— ëŒ€í•´ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
- ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json)ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- JSON ê°ì²´ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- ì‘ë‹µì€ ë°˜ë“œì‹œ {{ë¡œ ì‹œì‘í•˜ê³  }}ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
- ëª¨ë“  ë¬¸ìì—´ ê°’ì€ ë°˜ë“œì‹œ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì„¸ìš”.
- ì‘ë‹µì—ëŠ” ì˜¤ì§ JSON ë°ì´í„°ë§Œ í¬í•¨í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        else:
            json_prompt = prompt
        
        logger.info(f"ğŸ“¤ Gemini API í˜¸ì¶œ ì‹œì‘ - ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(json_prompt)}ì")
        logger.info(f"ğŸ”— API ì—°ê²° ìƒíƒœ: ì—°ê²° ì‹œë„ ì¤‘...")
        
        # sync_to_async ëŒ€ì‹  ì§ì ‘ ë¹„ë™ê¸° ì²˜ë¦¬
        def _call_model_sync() -> str:
            try:
                result = self._generative_model.generate_content(json_prompt)
                return result
            except Exception as exc:
                logger.error(f"âŒ Gemini í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}")
                logger.error(f"ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(exc).__name__}")
                logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {str(exc)}")
                raise GeminiServiceError(f"Gemini í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}") from exc

        # sync_to_async ëŒ€ì‹  ì§ì ‘ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œë„
        logger.info(f"ğŸ”„ ì§ì ‘ API í˜¸ì¶œ ì‹œì‘")
        
        try:
            # ì§ì ‘ generate_content í˜¸ì¶œ
            result = self._generative_model.generate_content(json_prompt)
            logger.info(f"âœ… ì§ì ‘ API í˜¸ì¶œ ì™„ë£Œ")
        except Exception as exc:
            logger.error(f"âŒ ì§ì ‘ API í˜¸ì¶œ ì‹¤íŒ¨: {exc}")
            logger.error(f"ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(exc).__name__}")
            logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {str(exc)}")
            raise GeminiServiceError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {exc}") from exc
        
        logger.info(f"âœ… Gemini API í˜¸ì¶œ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ì‘ë‹µ ê°ì²´ íƒ€ì…: {type(result)}")
        
        logger.info(f"ğŸ” ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘")
        text = getattr(result, "text", None)
        logger.info(f"ğŸ“ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼: {bool(text)}")
        
        if not text:
            logger.info(f"ğŸ” í›„ë³´ ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œì‘")
            # í›„ë³´ ì‘ë‹µ ì¤‘ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
            for i, candidate in enumerate(getattr(result, "candidates", []) or []):
                logger.info(f"ğŸ” í›„ë³´ {i+1} ê²€ì‚¬ ì¤‘...")
                for j, part in enumerate(getattr(candidate, "content", {}).get("parts", [])):
                    maybe_text = getattr(part, "text", None)
                    if maybe_text:
                        logger.info(f"âœ… í›„ë³´ {i+1}, íŒŒíŠ¸ {j+1}ì—ì„œ í…ìŠ¤íŠ¸ ë°œê²¬")
                        response = maybe_text
                        break
                if 'response' in locals():
                    break
            else:
                logger.warning("âš ï¸ Gemini ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                response = str(result)
        else:
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ - ê¸¸ì´: {len(text)}ì")
            response = text
        
        # JSON í˜•ì‹ì¸ ê²½ìš° í›„ì²˜ë¦¬ ìˆ˜í–‰
        if response_format == "json":
            response = self._clean_json_response(response)
        
        return response
    
    def _clean_json_response(self, response: str) -> str:
        """JSON ì‘ë‹µì„ ì •ë¦¬í•˜ì—¬ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        import re
        import json
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        cleaned = response.strip()
        
        # ```jsonìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
        if cleaned.startswith('```json'):
            cleaned = cleaned[7:]  # ```json ì œê±°
        elif cleaned.startswith('```'):
            cleaned = cleaned[3:]  # ``` ì œê±°
        
        # ```ë¡œ ëë‚˜ëŠ” ê²½ìš°
        if cleaned.endswith('```'):
            cleaned = cleaned[:-3]  # ``` ì œê±°
        
        # JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ {ë¶€í„° ë§ˆì§€ë§‰ }ê¹Œì§€)
        json_match = re.search(r'\{.*\}', cleaned, re.DOTALL)
        if json_match:
            cleaned = json_match.group(0)
        
        # ì œì–´ ë¬¸ì ì œê±° ë° ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        cleaned = self._sanitize_json_string(cleaned)
        
        return cleaned.strip()
    
    def _sanitize_json_string(self, json_str: str) -> str:
        """JSON ë¬¸ìì—´ì—ì„œ ì œì–´ ë¬¸ìë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        import json
        
        try:
            # ë¨¼ì € JSON íŒŒì‹±ì„ ì‹œë„í•˜ì—¬ ìœ íš¨ì„± ê²€ì‚¬
            json.loads(json_str)
            return json_str
        except json.JSONDecodeError:
            # ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
            sanitized = json_str.replace('\t', '\\t').replace('\n', '\\n').replace('\r', '\\r')
            
            # ì¶”ê°€ì ì¸ ì œì–´ ë¬¸ì ì²˜ë¦¬
            sanitized = ''.join(char if ord(char) >= 32 or char in '\t\n\r' else f'\\u{ord(char):04x}' 
                               for char in sanitized)
            
            return sanitized

    async def generate_embeddings_batch(
        self,
        texts: Iterable[str],
        *,
        task_type: str = "retrieval_document",
    ) -> List[List[float]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•œë‹¤."""

        payload = [text for text in texts if text and text.strip()]
        if not payload:
            return []

        async def _embed(text: str) -> Optional[List[float]]:
            def _call_embed() -> Optional[List[float]]:
                try:
                    response = genai.embed_content(
                        model=self.embedding_model,
                        content=text,
                        task_type=task_type,
                    )
                except Exception as exc:  # pragma: no cover - ì™¸ë¶€ API ì˜¤ë¥˜ ë˜í•‘
                    logger.error("Gemini ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: %s", exc)
                    raise GeminiServiceError(f"Gemini ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {exc}") from exc

                embedding = response.get("embedding") if isinstance(response, dict) else None
                if embedding is None:
                    logger.warning("Gemini ì„ë² ë”© ì‘ë‹µì— embedding í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return embedding

            return await sync_to_async(_call_embed, thread_sensitive=True)()

        embeddings: List[List[float]] = []
        for text in payload:
            vector = await _embed(text)
            if vector:
                embeddings.append(vector)

        return embeddings


_gemini_service_instance: Optional[GeminiService] = None


def get_gemini_service() -> GeminiService:
    """Gemini ì„œë¹„ìŠ¤ ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•œë‹¤."""

    global _gemini_service_instance
    if _gemini_service_instance is None:
        _gemini_service_instance = GeminiService()
        logger.info("Gemini ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    return _gemini_service_instance


