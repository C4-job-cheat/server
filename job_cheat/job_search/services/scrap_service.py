#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìŠ¤í¬ë© ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì‚¬ìš©ìê°€ ì¶”ì²œë°›ì€ ê³µê³ ë¥¼ ìŠ¤í¬ë©í•˜ê³ , ìŠ¤í¬ë©ëœ ê³µê³  ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, List, Any
from firebase_admin import firestore
from google.api_core import exceptions as google_exceptions

logger = logging.getLogger(__name__)

USER_COLLECTION = "users"
PERSONA_SUBCOLLECTION = "personas"
JOB_POSTINGS_COLLECTION = "job_postings"


class ScrapServiceError(RuntimeError):
    """ìŠ¤í¬ë© ì„œë¹„ìŠ¤ ê´€ë ¨ ì˜ˆì™¸."""


def add_job_to_scrap(user_id: str, persona_id: str, job_posting_id: str) -> Dict[str, Any]:
    """
    ê³µê³ ë¥¼ ìŠ¤í¬ë©ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        persona_id: í˜ë¥´ì†Œë‚˜ ID
        job_posting_id: ê³µê³  ID
        
    Returns:
        ìŠ¤í¬ë© ê²°ê³¼
    """
    try:
        logger.info(f"ğŸ“Œ ìŠ¤í¬ë© ì¶”ê°€ ì„œë¹„ìŠ¤ ì‹œì‘")
        logger.info(f"   ğŸ‘¤ user_id: {user_id}")
        logger.info(f"   ğŸ­ persona_id: {persona_id}")
        logger.info(f"   ğŸ’¼ job_posting_id: {job_posting_id}")
        
        logger.info(f"ğŸ”— Firestore í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œì‘")
        db = firestore.client()
        logger.info(f"âœ… Firestore í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì™„ë£Œ")
        
        # í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì°¸ì¡°
        logger.info(f"ğŸ“‹ í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì°¸ì¡° ìƒì„±")
        persona_ref = (
            db.collection(USER_COLLECTION)
            .document(user_id)
            .collection(PERSONA_SUBCOLLECTION)
            .document(persona_id)
        )
        logger.info(f"   ğŸ“ ê²½ë¡œ: users/{user_id}/personas/{persona_id}")
        
        # í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ
        logger.info(f"ğŸ“¤ í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ ì‹œì‘")
        persona_doc = persona_ref.get()
        
        if not persona_doc.exists:
            logger.error(f"âŒ í˜ë¥´ì†Œë‚˜ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {persona_id}")
            raise ScrapServiceError(f"í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_id}")
        
        logger.info(f"âœ… í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ")
        persona_data = persona_doc.to_dict()
        scrap_list = persona_data.get('scrap', [])
        logger.info(f"   ğŸ“Š ê¸°ì¡´ ìŠ¤í¬ë© ëª©ë¡ ê¸¸ì´: {len(scrap_list)}")
        logger.info(f"   ğŸ“‹ ê¸°ì¡´ ìŠ¤í¬ë© ëª©ë¡: {scrap_list}")
        
        # ì¤‘ë³µ ì²´í¬
        logger.info(f"ğŸ” ì¤‘ë³µ ì²´í¬ ì‹œì‘")
        if job_posting_id in scrap_list:
            logger.warning(f"âš ï¸ ì´ë¯¸ ìŠ¤í¬ë©ëœ ê³µê³ : {job_posting_id}")
            raise ScrapServiceError("ì´ë¯¸ ìŠ¤í¬ë©ëœ ê³µê³ ì…ë‹ˆë‹¤.")
        
        logger.info(f"âœ… ì¤‘ë³µ ì²´í¬ í†µê³¼")
        
        # ìŠ¤í¬ë© ëª©ë¡ì— ì¶”ê°€
        logger.info(f"ğŸ“ ìŠ¤í¬ë© ëª©ë¡ì— ì¶”ê°€ ì‹œì‘")
        scrap_list.append(job_posting_id)
        logger.info(f"   ğŸ“Š ì¶”ê°€ í›„ ìŠ¤í¬ë© ëª©ë¡ ê¸¸ì´: {len(scrap_list)}")
        logger.info(f"   ğŸ“‹ ì¶”ê°€ í›„ ìŠ¤í¬ë© ëª©ë¡: {scrap_list}")
        
        # í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸
        logger.info(f"ğŸ’¾ í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹œì‘")
        persona_ref.update({
            'scrap': scrap_list
        })
        logger.info(f"âœ… í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        logger.info(f"ğŸ‰ ìŠ¤í¬ë© ì¶”ê°€ ì™„ë£Œ: {job_posting_id}")
        
        return {
            "success": True,
            "message": "ê³µê³ ê°€ ì„±ê³µì ìœ¼ë¡œ ìŠ¤í¬ë©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "scrap_count": len(scrap_list)
        }
        
    except google_exceptions.GoogleAPICallError as exc:
        logger.error(f"ìŠ¤í¬ë© ì¶”ê°€ ì‹¤íŒ¨ (Firestore ì˜¤ë¥˜): {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë© ì¶”ê°€ ì‹¤íŒ¨: {exc}") from exc
    except Exception as exc:
        logger.error(f"ìŠ¤í¬ë© ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë© ì¶”ê°€ ì‹¤íŒ¨: {exc}") from exc


def remove_job_from_scrap(user_id: str, persona_id: str, job_posting_id: str) -> Dict[str, Any]:
    """
    ê³µê³ ë¥¼ ìŠ¤í¬ë©ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        persona_id: í˜ë¥´ì†Œë‚˜ ID
        job_posting_id: ê³µê³  ID
        
    Returns:
        ì œê±° ê²°ê³¼
    """
    try:
        logger.info(f"ìŠ¤í¬ë© ì œê±°: user_id={user_id}, persona_id={persona_id}, job_posting_id={job_posting_id}")
        
        db = firestore.client()
        
        # í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì°¸ì¡°
        persona_ref = (
            db.collection(USER_COLLECTION)
            .document(user_id)
            .collection(PERSONA_SUBCOLLECTION)
            .document(persona_id)
        )
        
        # í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ
        persona_doc = persona_ref.get()
        if not persona_doc.exists:
            raise ScrapServiceError(f"í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_id}")
        
        persona_data = persona_doc.to_dict()
        scrap_list = persona_data.get('scrap', [])
        
        # ìŠ¤í¬ë© ëª©ë¡ì—ì„œ ì œê±°
        if job_posting_id in scrap_list:
            scrap_list.remove(job_posting_id)
            
            # í˜ë¥´ì†Œë‚˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸
            persona_ref.update({
                'scrap': scrap_list
            })
            
            logger.info(f"ìŠ¤í¬ë© ì œê±° ì™„ë£Œ: {job_posting_id}")
            
            return {
                "success": True,
                "message": "ê³µê³ ê°€ ì„±ê³µì ìœ¼ë¡œ ìŠ¤í¬ë©ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "scrap_count": len(scrap_list)
            }
        else:
            raise ScrapServiceError("ìŠ¤í¬ë©ë˜ì§€ ì•Šì€ ê³µê³ ì…ë‹ˆë‹¤.")
        
    except google_exceptions.GoogleAPICallError as exc:
        logger.error(f"ìŠ¤í¬ë© ì œê±° ì‹¤íŒ¨ (Firestore ì˜¤ë¥˜): {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë© ì œê±° ì‹¤íŒ¨: {exc}") from exc
    except Exception as exc:
        logger.error(f"ìŠ¤í¬ë© ì œê±° ì¤‘ ì˜¤ë¥˜: {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë© ì œê±° ì‹¤íŒ¨: {exc}") from exc


def get_scraped_jobs(user_id: str, persona_id: str) -> List[Dict[str, Any]]:
    """
    ìŠ¤í¬ë©ëœ ê³µê³  ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        persona_id: í˜ë¥´ì†Œë‚˜ ID
        
    Returns:
        ìŠ¤í¬ë©ëœ ê³µê³  ëª©ë¡
    """
    try:
        logger.info(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ: user_id={user_id}, persona_id={persona_id}")
        
        db = firestore.client()
        
        # í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ
        persona_ref = (
            db.collection(USER_COLLECTION)
            .document(user_id)
            .collection(PERSONA_SUBCOLLECTION)
            .document(persona_id)
        )
        
        persona_doc = persona_ref.get()
        if not persona_doc.exists:
            raise ScrapServiceError(f"í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_id}")
        
        persona_data = persona_doc.to_dict()
        scrap_list = persona_data.get('scrap', [])
        
        if not scrap_list:
            logger.info("ìŠ¤í¬ë©ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ê° ìŠ¤í¬ë©ëœ ê³µê³ ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        scraped_jobs = []
        for job_posting_id in scrap_list:
            try:
                # ê³µê³  ìƒì„¸ ì •ë³´ ì¡°íšŒ
                job_posting_ref = db.collection(JOB_POSTINGS_COLLECTION).document(job_posting_id)
                job_posting_doc = job_posting_ref.get()
                
                if job_posting_doc.exists:
                    job_data = job_posting_doc.to_dict()
                    
                    # ìŠ¤í¬ë©ëœ ê³µê³  ì •ë³´ êµ¬ì„±
                    scraped_job = {
                        "job_posting_id": job_posting_id,
                        "company_name": job_data.get("company_name", ""),
                        "job_category": job_data.get("job_category", ""),
                        "job_title": job_data.get("job_title", ""),
                        "location": job_data.get("location", ""),
                        "requirements": job_data.get("requirements", []),
                        "preferred": job_data.get("preferred", []),
                        "deadline": job_data.get("deadline", ""),
                        "image_url": job_data.get("image_url", ""),
                        "company_logo": job_data.get("company_logo", ""),
                        "job_description": job_data.get("job_description", "")
                    }
                    
                    scraped_jobs.append(scraped_job)
                else:
                    logger.warning(f"ê³µê³  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {job_posting_id}")
                    
            except Exception as exc:
                logger.error(f"ê³µê³  ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({job_posting_id}): {exc}")
                continue
        
        logger.info(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ ì™„ë£Œ: {len(scraped_jobs)}ê°œ")
        return scraped_jobs
        
    except google_exceptions.GoogleAPICallError as exc:
        logger.error(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ ì‹¤íŒ¨ (Firestore ì˜¤ë¥˜): {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ ì‹¤íŒ¨: {exc}") from exc
    except Exception as exc:
        logger.error(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {exc}")
        raise ScrapServiceError(f"ìŠ¤í¬ë©ëœ ê³µê³  ì¡°íšŒ ì‹¤íŒ¨: {exc}") from exc
